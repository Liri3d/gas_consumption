# # modules/data_loader.py
# import streamlit as st
# import pandas as pd
# import numpy as np

# def render_sidebar():
#     """–†–µ–Ω–¥–µ—Ä–∏–Ω–≥ –±–æ–∫–æ–≤–æ–π –ø–∞–Ω–µ–ª–∏ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö"""
#     st.sidebar.subheader("üì• –ò–º–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö (UC-DAT-01)")
    
#     uploaded_file = st.sidebar.file_uploader(
#         "–ó–∞–≥—Ä—É–∑–∏—Ç–µ CSV —Ñ–∞–π–ª —Å –ø–æ–∫–∞–∑–∞–Ω–∏—è–º–∏ –ü–£", 
#         type="csv",
#         help="–§–æ—Ä–º–∞—Ç: —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å ';', –∫–æ–¥–∏—Ä–æ–≤–∫–∞ UTF-8"
#     )
    
#     if uploaded_file is not None:
#         load_data(uploaded_file)

# def load_data(uploaded_file):
#     """–ó–∞–≥—Ä—É–∑–∫–∞ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ CSV —Ñ–∞–π–ª–∞"""
#     try:
#         # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
#         df = pd.read_csv(
#             uploaded_file, 
#             sep=';', 
#             quotechar='"',
#             encoding='utf-8',
#             header=None,
#             names=["management", "subscriber_id", "md_id", "date", "gas_consumption", "source"]
#         )
        
#         # –í–∞–ª–∏–¥–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö
#         original_rows = len(df)
        
#         # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
#         duplicates = df.duplicated().sum()
#         if duplicates > 0:
#             st.sidebar.warning(f"–ù–∞–π–¥–µ–Ω–æ {duplicates} –¥—É–±–ª–∏–∫–∞—Ç–æ–≤. –ë—É–¥—É—Ç —É–¥–∞–ª–µ–Ω—ã.")
#             df = df.drop_duplicates()
        
#         # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–æ–ø—É—Å–∫–æ–≤
#         missing_values = df.isnull().sum().sum()
#         if missing_values > 0:
#             st.sidebar.warning(f"–ù–∞–π–¥–µ–Ω–æ {missing_values} –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π.")
        
#         # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
#         df['date_parsed'] = pd.to_datetime(df['date'], format='%d.%m.%Y', errors='coerce')
#         df['gas_consumption'] = pd.to_numeric(df['gas_consumption'], errors='coerce')
        
#         # –£–¥–∞–ª–µ–Ω–∏–µ –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
#         df = df.dropna(subset=['date_parsed', 'gas_consumption'])
        
#         # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ session_state
#         st.session_state.df = df
#         st.session_state.processed = True
        
#         st.sidebar.success(f"‚úÖ –î–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã: {len(df):,} –∑–∞–ø–∏—Å–µ–π")
#         st.sidebar.info(f"üìä –ü–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {len(df):,} –∏–∑ {original_rows:,} –∑–∞–ø–∏—Å–µ–π")
        
#         return df
        
#     except Exception as e:
#         st.sidebar.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: {str(e)}")
#         return None




# modules/db_loader.py
import streamlit as st
import pandas as pd
import numpy as np
import psycopg2
from datetime import datetime, timedelta
import os
from dotenv import load_dotenv

# –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
load_dotenv()

def get_db_connection():
    """–°–æ–∑–¥–∞–Ω–∏–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ PostgreSQL"""
    try:
        conn = psycopg2.connect(
            host=os.getenv("DB_HOST", "localhost"),
            database=os.getenv("DB_NAME", "gas_consumption"),
            user=os.getenv("DB_USER", "postgres"),
            password=os.getenv("DB_PASSWORD", ""),
            port=os.getenv("DB_PORT", "5432")
        )
        return conn
    except Exception as e:
        st.sidebar.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –ë–î: {str(e)}")
        return None

def render_sidebar():
    """–†–µ–Ω–¥–µ—Ä–∏–Ω–≥ –±–æ–∫–æ–≤–æ–π –ø–∞–Ω–µ–ª–∏ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö –∏–∑ –ë–î"""
    st.sidebar.subheader("üì• –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ –ë–î (UC-DAT-01)")
    
    # –ö–Ω–æ–ø–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö
    if st.sidebar.button("üîÑ –ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –∏–∑ –ë–î", key="load_db_data"):
        load_data_from_db()
    
    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
    st.sidebar.subheader("–§–∏–ª—å—Ç—Ä—ã –¥–∞–Ω–Ω—ã—Ö")
    
    col1, col2 = st.sidebar.columns(2)
    
    with col1:
        days_back = st.number_input(
            "–î–Ω–µ–π –Ω–∞–∑–∞–¥",
            min_value=1,
            max_value=365,
            value=30,
            help="–ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ N –¥–Ω–µ–π"
        )
    
    with col2:
        limit_rows = st.number_input(
            "–õ–∏–º–∏—Ç —Å—Ç—Ä–æ–∫",
            min_value=1000,
            max_value=1000000,
            value=100000,
            step=10000,
            help="–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏"
        )
    
    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
    auto_refresh = st.sidebar.checkbox(
        "–ê–≤—Ç–æ–æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö",
        value=False,
        help="–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–±–Ω–æ–≤–ª—è—Ç—å –¥–∞–Ω–Ω—ã–µ –∫–∞–∂–¥—ã–µ 30 –º–∏–Ω—É—Ç"
    )
    
    return {
        'days_back': days_back,
        'limit_rows': limit_rows,
        'auto_refresh': auto_refresh
    }

def load_data_from_db(days_back=30, limit_rows=100000):
    """–ó–∞–≥—Ä—É–∑–∫–∞ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ PostgreSQL"""
    try:
        with st.spinner("üì• –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ –ë–î..."):
            conn = get_db_connection()
            if conn is None:
                return None
            
            # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –¥–∞—Ç—É –Ω–∞—á–∞–ª–∞
            start_date = datetime.now() - timedelta(days=days_back)
            
            # SQL –∑–∞–ø—Ä–æ—Å –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö
            query = """
            SELECT 
                management,
                subscriber_id,
                meter_id as md_id,
                reading_date as date,
                consumption as gas_consumption,
                data_source as source,
                created_at
            FROM gas_readings
            WHERE reading_date >= %s
            ORDER BY reading_date DESC
            LIMIT %s
            """
            
            # –í—ã–ø–æ–ª–Ω—è–µ–º –∑–∞–ø—Ä–æ—Å
            df = pd.read_sql_query(query, conn, params=(start_date, limit_rows))
            conn.close()
            
            if df.empty:
                st.sidebar.warning("‚ö†Ô∏è –í –ë–î –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö –∑–∞ —É–∫–∞–∑–∞–Ω–Ω—ã–π –ø–µ—Ä–∏–æ–¥")
                return None
            
            # –í–∞–ª–∏–¥–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö
            original_rows = len(df)
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
            duplicates = df.duplicated().sum()
            if duplicates > 0:
                st.sidebar.warning(f"–ù–∞–π–¥–µ–Ω–æ {duplicates} –¥—É–±–ª–∏–∫–∞—Ç–æ–≤. –ë—É–¥—É—Ç —É–¥–∞–ª–µ–Ω—ã.")
                df = df.drop_duplicates()
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–æ–ø—É—Å–∫–æ–≤
            missing_values = df.isnull().sum().sum()
            if missing_values > 0:
                st.sidebar.warning(f"–ù–∞–π–¥–µ–Ω–æ {missing_values} –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π.")
            
            # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
            df['date_parsed'] = pd.to_datetime(df['date'], errors='coerce')
            df['gas_consumption'] = pd.to_numeric(df['gas_consumption'], errors='coerce')
            
            # –£–¥–∞–ª–µ–Ω–∏–µ –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
            df = df.dropna(subset=['date_parsed', 'gas_consumption'])
            
            # –î–æ–±–∞–≤–ª—è–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è
            df['year'] = df['date_parsed'].dt.year
            df['month'] = df['date_parsed'].dt.month
            df['day'] = df['date_parsed'].dt.day
            df['weekday'] = df['date_parsed'].dt.weekday
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ session_state
            st.session_state.df = df
            st.session_state.processed = True
            st.session_state.last_update = datetime.now()
            
            st.sidebar.success(f"‚úÖ –î–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã: {len(df):,} –∑–∞–ø–∏—Å–µ–π")
            st.sidebar.info(f"üìä –ü–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {len(df):,} –∏–∑ {original_rows:,} –∑–∞–ø–∏—Å–µ–π")
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
            st.session_state.data_meta = {
                'loaded_at': datetime.now(),
                'total_records': len(df),
                'date_range': {
                    'min': df['date_parsed'].min(),
                    'max': df['date_parsed'].max()
                },
                'unique_subscribers': df['subscriber_id'].nunique(),
                'unique_managements': df['management'].nunique()
            }
            
            return df
            
    except Exception as e:
        st.sidebar.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∏–∑ –ë–î: {str(e)}")
        return None

def get_available_managements():
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —É–ø—Ä–∞–≤–ª–µ–Ω–∏–π –∏–∑ –ë–î"""
    try:
        conn = get_db_connection()
        if conn is None:
            return []
        
        query = "SELECT DISTINCT management FROM gas_readings ORDER BY management"
        df = pd.read_sql_query(query, conn)
        conn.close()
        
        return df['management'].tolist()
    except:
        return []

def get_subscriber_data(subscriber_id):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –ø–æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–º—É –∞–±–æ–Ω–µ–Ω—Ç—É"""
    try:
        conn = get_db_connection()
        if conn is None:
            return None
        
        query = """
        SELECT * FROM gas_readings 
        WHERE subscriber_id = %s 
        ORDER BY reading_date DESC
        LIMIT 1000
        """
        
        df = pd.read_sql_query(query, conn, params=(subscriber_id,))
        conn.close()
        
        return df
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –∞–±–æ–Ω–µ–Ω—Ç–∞: {str(e)}")
        return None

def save_analysis_results(results, analysis_type):
    """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞ –≤ –ë–î"""
    try:
        conn = get_db_connection()
        if conn is None:
            return False
        
        cursor = conn.cursor()
        
        # –°–æ–∑–¥–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞, –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç
        create_table_query = """
        CREATE TABLE IF NOT EXISTS analysis_results (
            id SERIAL PRIMARY KEY,
            analysis_type VARCHAR(50),
            subscriber_id VARCHAR(50),
            cluster_id INTEGER,
            anomaly_score FLOAT,
            forecast_value FLOAT,
            confidence_interval JSON,
            analysis_date TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            metadata JSON
        )
        """
        cursor.execute(create_table_query)
        
        # –ó–¥–µ—Å—å –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –ª–æ–≥–∏–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        # –í –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç analysis_type
        
        conn.commit()
        cursor.close()
        conn.close()
        
        return True
        
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {str(e)}")
        return False